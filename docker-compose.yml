version: "3.8"

services:
  # ================= MySQL =================
  mysql:
    image: quay.io/debezium/example-mysql:1.9
    ports:
      - "3306:3306"
    environment:
      - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}
      - MYSQL_USER=${MYSQL_USER}
      - MYSQL_PASSWORD=${MYSQL_PASSWORD}
      - MYSQL_DATABASE=${MYSQL_DATABASE}
    networks:
      - app-network
    volumes:
      - ./init:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "root", "-p${MYSQL_ROOT_PASSWORD}"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s
    restart: unless-stopped

  # ================= Kafka + Debezium + Schema Registry =================
  zookeeper:
    image: confluentinc/cp-zookeeper:5.5.3
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    networks:
      - app-network
    restart: unless-stopped

  kafka:
    image: confluentinc/cp-enterprise-kafka:5.5.3
    environment:
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_BROKER_ID: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9991
    ports:
      - "9092:9092"
    networks:
      - app-network
    depends_on:
      - zookeeper
    restart: unless-stopped

  connect:
    image: quay.io/debezium/connect:1.9
    ports:
      - "8083:8083"
    environment:
      - BOOTSTRAP_SERVERS=kafka:9092
      - GROUP_ID=1
      - CONFIG_STORAGE_TOPIC=my_connect_configs
      - OFFSET_STORAGE_TOPIC=my_connect_offsets
      - STATUS_STORAGE_TOPIC=my_connect_statuses
    volumes: 
      - ${PWD}/kconnect-jdbc-sink-jars:/kafka/connect/kconnect-jdbc-sink-jars
      - ${PWD}/kconnect-s3-sink-jars:/kafka/connect/kconnect-s3-sink-jars
      - ${PWD}/confluentic-connect-transforms:/kafka/connect/confluentic-connect-transforms
    networks:
      - app-network
    depends_on:
      - kafka
      - mysql
    restart: unless-stopped

  schema-registry:
    image: confluentinc/cp-schema-registry:5.5.3
    environment:
      - SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL=zookeeper:2181
      - SCHEMA_REGISTRY_HOST_NAME=schema-registry
      - SCHEMA_REGISTRY_LISTENERS=http://schema-registry:8081,http://localhost:8081
    ports:
      - "8081:8081"
    networks:
      - app-network
    depends_on:
      - zookeeper
      - kafka
    restart: unless-stopped

  # ================= Stroke Prediction API =================
  stroke-prediction-api:
    build: .
    container_name: stroke-prediction-api
    ports:
      - "8000:8000"
    volumes:
      - ./fast_api:/app/fast_api
      - ./models:/app/models
    working_dir: /app/fast_api
    environment:
      - PYTHONPATH=/app
      - PYTHONUNBUFFERED=1
      - MYSQL_HOST=${MYSQL_HOST}
      - MYSQL_PORT=${MYSQL_PORT}
      - MYSQL_DATABASE=${MYSQL_DATABASE}
      - MYSQL_USER=${MYSQL_USER}
      - MYSQL_PASSWORD=${MYSQL_PASSWORD}
    networks:
      - app-network
    depends_on:
      mysql:
        condition: service_healthy
    restart: on-failure
    command: >
      sh -c "sleep 15 && uvicorn main:app --host 0.0.0.0 --port 8000 --reload"
    healthcheck:
      test: ["CMD-SHELL", "python -c 'import urllib.request; urllib.request.urlopen(\"http://localhost:8000/model_info\")' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s

  # ================= Spark Cluster + PySpark Notebook =================
  spark:
    image: bitnami/spark:3.5.1
    hostname: spark
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - "7077:7077"
      - "8080:8080"
    networks:
      - app-network
      - spark
    restart: unless-stopped

  spark-worker-1:
    image: bitnami/spark:3.5.1
    container_name: spark-worker-1
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
    networks:
      - app-network
      - spark
    depends_on:
      - spark
    restart: unless-stopped

  pyspark:
    image: jupyter/pyspark-notebook:latest
    container_name: pyspark
    hostname: pyspark
    ports:
      - "9999:8888"
    volumes:
      - ./notebooks:/home/jovyan/work
    environment:
      - JUPYTER_ENABLE_LAB=no
      - PYSPARK_SUBMIT_ARGS=--packages org.apache.spark:spark-avro_2.12:3.5.1,org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262 pyspark-shell
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION}
    networks:
      - app-network
      - spark
    depends_on:
      - spark
    restart: unless-stopped

# ================= Networks =================
networks:
  app-network:
    driver: bridge
  spark:
    driver: bridge
